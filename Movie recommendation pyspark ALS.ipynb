{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import require libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pyspark import SparkContext \n",
    "from pyspark.sql import SQLContext \n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import min, avg\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download dataset from https://www.kaggle.com/grouplens/movielens-20m-dataset/download/Mik23vvybMVT1WnMyUaB%2Fversions%2FSkDpcTj1HRLUw6J3MKQ8%2Ffiles%2Frating.csv?datasetVersionNumber=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate context and load the data\n",
    "sc = SparkContext()\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "# Due to computational efficiency loading only few records\n",
    "ratings = sqlContext.read.format('com.databricks.spark.csv').options(header='true').load('rating.csv').limit(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the column names\n",
    "print(ratings.columns)\n",
    "\n",
    "# Look at the first few rows of data\n",
    "print(ratings.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the total number of ratings in the dataset\n",
    "numerator = ratings.select(\"rating\").count()\n",
    "\n",
    "# Count the number of distinct userIds and distinct movieIds\n",
    "num_users = ratings.select(\"userID\").distinct().count()\n",
    "num_movies = ratings.select(\"movieID\").distinct().count()\n",
    "\n",
    "# Set the denominator equal to the number of users multiplied by the number of movies\n",
    "denominator = num_users * num_movies\n",
    "\n",
    "# Divide the numerator by the denominator\n",
    "sparsity = (1.0 - (numerator *1.0)/denominator)*100\n",
    "print(\"The ratings dataframe is \", \"%.2f\" % sparsity + \"% empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the requisite packages\n",
    "\n",
    "# View the ratings dataset\n",
    "ratings.show()\n",
    "\n",
    "# Filter to show only userIds less than 100\n",
    "ratings.filter(col(\"userId\") < 100).show()\n",
    "\n",
    "# Group data by userId, count ratings\n",
    "ratings.groupBy(\"userId\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min num ratings for movies\n",
    "print(\"Movie with the fewest ratings: \")\n",
    "ratings.groupBy(\"movieId\").count().select(min(\"count\")).show()\n",
    "\n",
    "# Avg num ratings per movie\n",
    "print(\"Avg num ratings per movie: \")\n",
    "ratings.groupBy(\"movieId\").count().select(avg(\"count\")).show()\n",
    "\n",
    "# Min num ratings for user\n",
    "print(\"User with the fewest ratings: \")\n",
    "ratings.groupBy(\"userId\").count().select(min(\"count\")).show()\n",
    "\n",
    "# Avg num ratings per users\n",
    "print(\"Avg num ratings per user: \")\n",
    "ratings.groupBy(\"userId\").count().select(avg(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use .printSchema() to see the datatypes of the ratings dataset\n",
    "ratings.printSchema()\n",
    "\n",
    "# Tell Spark to convert the columns to the proper data types\n",
    "ratings = ratings.select(ratings.userId.cast(\"integer\"), ratings.movieId.cast(\"integer\"), ratings.rating.cast(\"double\"))\n",
    "\n",
    "# Call .printSchema() again to confirm the columns are now in the correct format\n",
    "ratings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create training and test set (80/20 split)\n",
    "(training, test) = ratings.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Build generic ALS model without hyperparameters\n",
    "als = ALS(userCol=\"userId\", \n",
    "          itemCol=\"movieId\", \n",
    "          ratingCol=\"rating\", \n",
    "          coldStartStrategy=\"drop\" , \n",
    "          nonnegative = True,\n",
    "          implicitPrefs = False)\n",
    "\n",
    "# Fit model to training data\n",
    "model = als.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on test_data\n",
    "predictions = model.transform(test)\n",
    "\n",
    "# Tell Spark how to evaluate predictions\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "\n",
    "# Obtain and print RMSE\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print (\"RMSE: \"), rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CrossValidator and ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "(training_data, test_data) = ratings.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Create ALS model\n",
    "als = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", nonnegative = True, implicitPrefs = False)\n",
    "\n",
    "# Confirm that a model called \"als\" was created\n",
    "type(als)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add hyperparameters and their respective values to param_grid\n",
    "# Note:- more parameters can be added. For faster execution kept limited parameters\n",
    "param_grid = ParamGridBuilder() \\\n",
    "            .addGrid(als.rank, [5, 40, 80, 120]) \\\n",
    "            .addGrid(als.maxIter, [5, 100, 250, 500]) \\\n",
    "            .addGrid(als.regParam, [.05, .1, 1.5]) \\\n",
    "            .build()\n",
    "           \n",
    "# Define evaluator as RMSE and print length of evaluator\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\") \n",
    "print (\"Num models to be tested: \", len(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Build cross validation using CrossValidator\n",
    "cv = CrossValidator(estimator=als, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=3)\n",
    "\n",
    "# Fit model to training data\n",
    "model = cv.fit(training_data)\n",
    "\n",
    "# Extract best combination of values from cross validation\n",
    "best_model = model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print best_model\n",
    "print(type(cv.best_model))\n",
    "\n",
    "# Complete the code below to extract the ALS model parameters\n",
    "print(\"**Best Model**\")\n",
    "\n",
    "# Print \"Rank\"\n",
    "print(\"  Rank:\", best_model.getRank())\n",
    "\n",
    "# Print \"MaxIter\"\n",
    "print(\"  MaxIter:\", best_model.getMaxIter())\n",
    "\n",
    "# Print \"RegParam\"\n",
    "print(\"  RegParam:\", best_model.getRegParam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the predictions \n",
    "test_predictions.show()\n",
    "\n",
    "# Calculate and print the RMSE of test_predictions\n",
    "RMSE = evaluator.evaluate(test_predictions)\n",
    "print(RMSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
